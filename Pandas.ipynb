{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What is Pandas?\n",
        "---\n",
        "\n",
        "From https://pandas.pydata.org/pandas-docs/stable:\n",
        "\n",
        "> pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with \u201crelational\u201d or \u201clabeled\u201d data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language. It is already well on its way toward this goal.\n",
        ">\n",
        "> pandas is well suited for many different kinds of data:\n",
        ">\n",
        "> - Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\n",
        "> - Ordered and unordered (not necessarily fixed-frequency) time series data.\n",
        "> - Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\n",
        "> - Any other form of observational / statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure\n",
        "\n",
        "Personally, I use Pandas to work with tabular data. Why choose Pandas over a spreadsheet program (e.g. Excel)?\n",
        "\n",
        "- Pandas is open source and free\n",
        "- One can store __reproducible__ steps to get from an input to an output\n",
        "    - Excel will only store the final state, not the steps to get there!\n",
        "- It is less memory intensive and you can work with larger datasets\n",
        "\n",
        "### Pandas is built on NumPy\n",
        "\n",
        "NumPy provides multidimensional list-like data structures which are typed and much faster than Python lists. Pandas was built on top of NumPy and in an extremely similar fashion. The data structures provided in both libraries operate almost interchangably and we will simply discuss Pandas. Keep in mind almost all you learn today is similar, or exactly the same, in NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing Pandas\n",
        "---\n",
        "\n",
        "First, you need to `import pandas`. By convention, it is imported using the _alias_ `pd`. To import using an alias use the following syntax:\n",
        "\n",
        "```python\n",
        "import <library> as <alias>\n",
        "```\n",
        "\n",
        "- Many libraries follow an alias convention, check their documentation\n",
        "\n",
        "#### Tasks:\n",
        "\n",
        "1. Can you import `pandas` using the conventional alias?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Structures\n",
        "---\n",
        "\n",
        "Similar to the Python data structures (e.g. `list, dictionary, set`), Pandas provides three fundamental data structures:\n",
        "\n",
        "1. `Series`: For one-dimensional data, similar to a `list` or NumPy array\n",
        "2. `DataFrame`: For two-dimensional data, similar to a `dictionary` or 2d NumPy Array\n",
        "3. `Index`: Similar to a `Series`, but for naming, selecting, and transforming data within a `Series` or `DataFrame`\n",
        "\n",
        "### Series\n",
        "\n",
        "You can create a Pandas `Series` in a variety of ways, e.g.:\n",
        "\n",
        "- From an assigned Python list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = ['a', 'b', 'c']\n",
        "series = pd.Series(a)\n",
        "series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- From an unnamed Python list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "series = pd.Series([4, 5, 6])\n",
        "series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Using a specific index (similar to `dict` where the index are the keys):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "series = pd.Series([4, 5, 6], index=['a', 'b', 'c'])\n",
        "series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Directly from a dictionary (exactly the same as above):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "series = pd.Series({'a': 4, 'b': 5, 'c': 6})\n",
        "series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataFrame\n",
        "\n",
        "This is the data structure that makes Pandas shine. A `DataFrame` is essentially a dictionary of `Series` objects. In a `DataFrame`, the `keys` map to `Series` objects which share a common `index`. We should start with an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rock_bands = ['Pink Floyd', 'Rush', 'Yes']\n",
        "year_formed = [1965, 1968, 1968]\n",
        "location_formed = ['London, England', 'Ontario, Canada', 'London, England']\n",
        "df = pd.DataFrame({'year_formed': year_formed, 'location_formed': location_formed}, index=rock_bands)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Breaking Down the Result\n",
        "\n",
        "- The indicies are `'Pink Floyd'`, `'Rush'`, and `'Yes'`\n",
        "- The keys to the data frame are `'year_formed'` and `'location_formed'`\n",
        "- The lists are converted to `Series` objects which share the indices\n",
        "\n",
        "This might not seem very powerful, except that `DataFrame`s can be constructed from files! In a previous task, you were asked to read a file `states.csv` then parse it manually and do some statistics. In the following cell, I will read the file and generate statistics in two lines!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('states.csv')\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "1. Use `pd.read_csv` to read in the csv file: `example.bsv`\n",
        "    - It does not contain a header (add `header=None` to the arguments)\n",
        "    - By convention `DataFrame`s are assigned to the name `df`\n",
        "    - The file is bar separated (add `sep='|'` to the arguments)\n",
        "    - Lastly set the column names (add `names=['First', 'Second']`)\n",
        "    - Make sure you look at the result!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Viewing DataFrames\n",
        "---\n",
        "\n",
        "Jupyter has built in support for viewing `DataFrame` objects in a nice format. Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame([0, 1, 2], index=[5, 6, 7], columns=['Example'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result should have been a nice looking table. Reminders:\n",
        "\n",
        "- The above `DataFrame` contains a single `Series` with the key `Example`\n",
        "- The indices are on the left (in bold)\n",
        "- The values are in columns underneath the key\n",
        "\n",
        "If you only want to view a subset of the DataFrame, you can use the syntax `<df>.head()`. By default it will print only 5 rows from the top of your DataFrame. This is very useful when trying to view the _shape_ of your data. You can print fewer rows by adding `n=<number>` to the arguments of `head`.\n",
        "\n",
        "### Tasks\n",
        "\n",
        "- Run the definitions cell below\n",
        "- Print the DataFrame in the following ways:\n",
        "    - Using the built in Jupyter view\n",
        "    - The head\n",
        "    - The first row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definitions\n",
        "l = list(range(10))\n",
        "df = pd.DataFrame({'a': l, 'b': l, 'c': l})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Access and Types\n",
        "\n",
        "You can access `Series` from `DataFrame`s using two syntax:\n",
        "\n",
        "- Like a dictionary: `<df>['<key>']`\n",
        "- Like a data member, `<df>.<key>`\n",
        "\n",
        "Important note: do not assign keys to values using the data member style! That style is for access only! For this reason, I tend to prefer the dictionary style.\n",
        "\n",
        "If you want to know the types of your `DataFrame`'s `Series`s using `<df>.dtypes`\n",
        "\n",
        "### Tasks\n",
        "\n",
        "- Run the definitions cell below\n",
        "- Access `b` of `df` using both styles\n",
        "- Why are two columns printed?\n",
        "- What is the type of `df['b']`?\n",
        "- What are the `dtypes` of `df`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definitions\n",
        "df = pd.DataFrame({'a': [0, 1, 2], 'b': [0.0, 1.0, 2.0], 'c': [\"pandas\", \"is\", \"great\"]})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Slicing and Indexing\n",
        "---\n",
        "\n",
        "There are many ways to slice and dice DataFrames. Let's start with the least flexible option, selecting multiple columns. Let's make a new DataFrame in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
        "example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To slice columns `a` and `c` we'll use a similar syntax to the dictionary access, shown before, but instead we will ask for a list of columns instead of a single one, e.g. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example[['a', 'c']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One can also slice rows using a `list`-like syntax. Note you are __required__ to specify a slice (something containing '`:`'). For example,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# zeroth row only\n",
        "example[0:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# first row to end\n",
        "example[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# every other row\n",
        "example[::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this will fail with `KeyError`\n",
        "# -> remember this is dictionary style access and `0` isn't a key!\n",
        "example[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "More Complicated Access Patterns\n",
        "---\n",
        "\n",
        "You can narrow down rows and columns using `loc`, some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# only row 1, columns 'a' and 'c'\n",
        "example.loc[1:1, ['a', 'c']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# all rows, columns 'a' to 'b'\n",
        "example.loc[:, 'a':'b']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# single row, single column\n",
        "example.loc[0, 'a']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "Using `loc` and the `example` DataFrame,\n",
        "\n",
        "1. Can you get every other row, columns `b` to `c`?\n",
        "2. Can you get the last row, all columns?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Note\n",
        "\n",
        "`loc` is all about index/key access, what if the indices are characters? Run the following cell and then complete the tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example2 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]}, index=['A', 'B', 'C'])\n",
        "example2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "Use `loc` and DataFrame `example2`, to\n",
        "\n",
        "- Print rows `B` to `C` and columns `a` to `b`.\n",
        "- What happens if you try to access the index numerically?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes\n",
        "\n",
        "To access `example2` w/ numerical indices, we need `iloc`.\n",
        "\n",
        "### Tasks\n",
        "\n",
        "1. Using `iloc` and `example2`, get rows `B` to `C` and columns `a` to `b`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes\n",
        "\n",
        "You can also use the `list` style access I showed before, e.g."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example2.iloc[[1, 2], [0, 1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Access by Boolean Arrays\n",
        "---\n",
        "\n",
        "- One can use a boolean numpy array to access subsets of `DataFrame`s\n",
        "- First, I will define a `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'hello': [0, 1, 2], 'world': [3, 4, 5]}, index=['top', 'middle', 'bottom'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- I can generate a boolean array using _dispatch_\n",
        "- The following line will test if each index is equal to `'middle'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.index == 'middle'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- What is the type and dtype?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = (df.index == 'middle')\n",
        "type(arr), arr.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- One can use these `bool` arrays to downselect `DataFrame`s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.index == 'middle']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- You can also compose multiple criterion together, e.g.\n",
        "    - `|` is `or`\n",
        "    - `&` is `and`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[(df.index == 'middle') | (df.index == 'top')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "- Run the definitions cell\n",
        "- Access the `DataFrame` where column `'a'` is greater than or equal to 2\n",
        "- Access row `'B'` where row `'B'` is greater than or equal to 5\n",
        "- Access the `DataFrame` where column `'a'` is greater than 2 and column `'b'` is less than 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]}, index=['A', 'B', 'C'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Built-in Statistics\n",
        "---\n",
        "\n",
        "Coming back to the original example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states = pd.read_csv('states.csv', index_col=0)\n",
        "states.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- One can easily access the statistics of the entire `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- There is 52 states according to the count. The mean population is about 6.3 million people for 2016 and 2017\n",
        "- It is also possible to down select the statistics, e.g. if I want the mean for Population 2016"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states['Population (2016)'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "- Find the state with\n",
        "    - the smallest population in 2016\n",
        "    - the largest population in 2017\n",
        "- Is it the same for 2017?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding New Columns\n",
        "---\n",
        "\n",
        "What if what we really wanted was the average population per state for 2016 and 2017?\n",
        "\n",
        "- We can use a dispatched operation similar to the `==` example previous to generate the averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(states['Population (2016)'] + states['Population (2017)']) / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The above is a `Series` object. We can assign it to a `key` in the `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states['Average Population'] = (states['Population (2016)'] + states['Population (2017)']) / 2\n",
        "states['Average Population'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Finally the overall mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states['Average Population'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Viewing Data\n",
        "---\n",
        "\n",
        "Pandas plugs into `matplotlib` very nicely. I am going to iteratively build a plot which is easy to read. First, run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states = pd.read_csv('states.csv', index_col=0)\n",
        "states.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is something, but not very helpful. What would we like:\n",
        "\n",
        "- X axis should be labeled with the state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = states.plot(subplots=True, xticks=range(states.shape[0]))\n",
        "suppressing_output = ax[0].set_xticklabels(states.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notes\n",
        "---\n",
        "\n",
        "1. `subplots=True`: separates the 2 plots from one another\n",
        "2. `xticks=range(states.shape[0])`: sets all of the ticks on the x-axis\n",
        "3. `ax = ...`: is a list containing both plots\n",
        "4. `ax[0].set_xticklables` changes the numeric index to the State name, should only be necessary for the 0th plot\n",
        "5. `suppressing_output = ...`, I use this to supress the output from `set_xticklabels`\n",
        "\n",
        "\n",
        "Neat, but I can't read the labels..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = states.plot(subplots=True, xticks=range(states.shape[0]), figsize=(20, 10))\n",
        "suppressing_output = ax[0].set_xticklabels(states.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The line plots are a little awkward because the points aren't connected in anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = states.plot(subplots=True, xticks=range(states.shape[0]), figsize=(20, 10), kind='bar')\n",
        "suppressing_output = ax[0].set_xticklabels(states.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Not bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply + Lambda\n",
        "---\n",
        "\n",
        "I want to briefly show you a decent idiom for doing more complicated work on a `Series`.\n",
        "\n",
        "This is a contrived example, but it shows the utility of `apply` + `lambda`.\n",
        "\n",
        "What if we wanted wanted to figure out if all letters A-Z are in the names of the states? First, we could create a `set` of characters in each state's name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# don't use the names of states an the index!\n",
        "states = pd.read_csv('states.csv')\n",
        "\n",
        "def set_of_chars(s):\n",
        "    return set(list(s.lower()))\n",
        "\n",
        "series_of_sets = states.State.apply(lambda s: set_of_chars(s))\n",
        "series_of_sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I need to combine all of these sets into a single one!\n",
        "\n",
        "- First, an example of combining sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = {1, 2, 3}\n",
        "b = {2, 4}\n",
        "a.union(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we are going to \"reduce\" the `list` of `set`s by taking the union of each entry. If done step by step:\n",
        "\n",
        "```python\n",
        "_tmp = <zeroth_set>.union(<first_set>)\n",
        "_tmp = _tmp.union(<second_set>)\n",
        "_tmp = _tmp.union(<third_set>)\n",
        "...\n",
        "_tmp = _tmp.union(<final_set>)\n",
        "```\n",
        "\n",
        "Remember, we are going to use `reduce` from `functools` and an anonymous function to take the union between the sets to generate a single set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "chars_used_in_states_name = reduce(lambda x, y: x.union(y), series_of_sets)\n",
        "chars_used_in_states_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, we need to remove any non-alphanumeric characters\n",
        "\n",
        "- `ascii_lowercase` from `string` is simply a string of all of the characters\n",
        "    - i.e.\n",
        "        - `\" \" in ascii_lowercase` would return `False`\n",
        "        - `\"a\" in ascii_lowercase` would return `True`\n",
        "- We can use a set comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from string import ascii_lowercase\n",
        "chars_used_in_states_name = {x for x in chars_used_in_states_name if x in ascii_lowercase}\n",
        "chars_used_in_states_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now we can answer our question!\n",
        "\n",
        "Are all of the characters used in the states names?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alphabet_set = set(list(ascii_lowercase))\n",
        "alphabet_set.difference(chars_used_in_states_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The concepts of reductions and anonymous functions can be very useful when doing data analysis! Many times you can use comprehensions to do something similar, but I personally enjoy the `reduce` style. No tasks for this section. I would suggest prodding the above code to make sure you understand it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Built-in Methods and Axis\n",
        "---\n",
        "\n",
        "There are many built-in methods in Pandas, for example `.mean()`. By default, these methods operate on the columns with an argument called the `axis` with a default value of `0`. You can generate row based means with `axis=1`.\n",
        "\n",
        "### Tasks\n",
        "\n",
        "- Run the definitions cell\n",
        "- Generate the column and row means for `states` using the axis argument\n",
        "- Generate the DataFrame mean, i.e. a single value, for `states`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definitions\n",
        "states = pd.read_csv('states.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Writing Files\n",
        "---\n",
        "\n",
        "CSV files are a standard way to share data, one can write a `DataFrame` to a CSV file using the syntax:\n",
        "\n",
        "```python\n",
        "<DataFrame>.to_csv(<filename.csv>)\n",
        "```\n",
        "\n",
        "Notes:\n",
        "\n",
        "- The seperator, by default, is a comma. Try `sep='|'` argument, use a '.bsv' ending\n",
        "- To not include the index, use `index=None`\n",
        "- To not include a header, use `header=None`\n",
        "\n",
        "### Tasks\n",
        "\n",
        "- Run the definitions cell\n",
        "- Write the `states` DataFrame to a file called \"intro.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definitions\n",
        "states = pd.read_csv('states.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
